{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYaWQq05cymN"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/afnan47/cuda.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee2T8lsDc3PH",
        "outputId": "ff83942c-004f-47ee-edf3-3a96a2129d19"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-dh4zegft\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-dh4zegft\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=03319d80d308afb952a90d5355755b08bbae9de4948d72a205beb67b372d9e2b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pancj_8m/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joMLO7Fuc5Mn",
        "outputId": "3ec50699-4c2a-445b-f359-6d4e6ab443a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "#include <iostream>\n",
        "#include <cstdlib> // Include <cstdlib> for rand()\n",
        "using namespace std;\n",
        "__global__\n",
        "void add(int* A, int* B, int* C, int size) {\n",
        "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "if (tid < size) {\n",
        "C[tid] = A[tid] + B[tid];\n",
        "}\n",
        "}\n",
        "void print(int* vector, int size) {\n",
        "for (int i = 0; i < size; i++) {\n",
        "cout << vector[i] << \" \";\n",
        "}\n",
        "cout << endl;\n",
        "}\n",
        "int main() {\n",
        "int N;\n",
        "cout << \"Enter the size of the vectors: \";\n",
        "cin >> N;\n",
        "int* A, * B, * C;\n",
        "int vectorSize = N;\n",
        "size_t vectorBytes = vectorSize * sizeof(int);\n",
        "// Allocate host memory\n",
        "A = new int[vectorSize];\n",
        "B = new int[vectorSize];\n",
        "C = new int[vectorSize];\n",
        "// Initialize host arrays\n",
        "cout << \"Enter elements of vector A:\" << endl;\n",
        "for (int i = 0; i < N; i++) {\n",
        "cin >> A[i];\n",
        "}\n",
        "cout << \"Enter elements of vector B:\" << endl;\n",
        "for (int i = 0; i < N; i++) {\n",
        "cin >> B[i];\n",
        "}\n",
        "cout << \"Vector A: \";\n",
        "print(A, N);\n",
        "cout << \"Vector B: \";\n",
        "print(B, N);\n",
        "int* X, * Y, * Z;\n",
        "// Allocate device memory\n",
        "cudaMalloc(&X, vectorBytes);\n",
        "cudaMalloc(&Y, vectorBytes);\n",
        "cudaMalloc(&Z, vectorBytes);\n",
        "// Check for CUDA memory allocation errors\n",
        "if (X == nullptr || Y == nullptr || Z == nullptr) {\n",
        "cerr << \"CUDA memory allocation failed\" << endl;\n",
        "return 1;\n",
        "}\n",
        "// Copy data from host to device\n",
        "cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);\n",
        "int threadsPerBlock = 256;\n",
        "int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "// Launch kernel\n",
        "add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N);\n",
        "// Check for kernel launch errors\n",
        "cudaError_t kernelLaunchError = cudaGetLastError();\n",
        "if (kernelLaunchError != cudaSuccess) {\n",
        "cerr << \"CUDA kernel launch failed: \" <<\n",
        "cudaGetErrorString(kernelLaunchError) << endl;\n",
        "return 1;\n",
        "}\n",
        "// Copy result from device to host\n",
        "cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);\n",
        "// Check for CUDA memcpy errors\n",
        "cudaError_t memcpyError = cudaGetLastError();\n",
        "if (memcpyError != cudaSuccess) {\n",
        "cerr << \"CUDA memcpy failed: \" << cudaGetErrorString(memcpyError) <<\n",
        "endl;\n",
        "return 1;\n",
        "}\n",
        "cout << \"Addition: \";\n",
        "print(C, N);\n",
        "// Free device memory\n",
        "cudaFree(X);\n",
        "cudaFree(Y);\n",
        "cudaFree(Z);\n",
        "// Free host memory\n",
        "delete[] A;\n",
        "delete[] B;\n",
        "delete[] C;\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5bVn_KOc7eH",
        "outputId": "7a9e1c93-07bc-467c-9d92-9f36d1677cf7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc add.cu -o add"
      ],
      "metadata": {
        "id": "Ya0Qkj9ydKk0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjR3acdMdNYn",
        "outputId": "fdb6ff48-0d53-4347-b9a7-ba2a3801cbf4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the size of the vectors: 3\n",
            "Enter elements of vector A:\n",
            "\n",
            "1 4 7\n",
            "Enter elements of vector B:\n",
            "2 4 3\n",
            "Vector A: 1 4 7 \n",
            "Vector B: 2 4 3 \n",
            "Addition: 3 8 10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mult.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "using namespace std;\n",
        "#define BLOCK_SIZE 1\n",
        "__global__ void gpuMM(float *A, float *B, float *C, int N) {\n",
        "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "float sum = 0.f;\n",
        "for (int n = 0; n < N; ++n)\n",
        "sum += A[row * N + n] * B[n * N + col];\n",
        "C[row * N + col] = sum;\n",
        "}\n",
        "int main(int argc, char *argv[]) {\n",
        "int N;\n",
        "// Get matrix size from user\n",
        "cout << \"Enter size of matrix (N): \";\n",
        "cin >> N;\n",
        "if (N % BLOCK_SIZE != 0) {\n",
        "cerr << \"Matrix size must be a multiple of BLOCK_SIZE.\" << endl;\n",
        "return 1;\n",
        "}\n",
        "cout << \"\\nExecuting Matrix Multiplication\" << endl;\n",
        "cout << \"Matrix size: \" << N << \"x\" << N << endl;\n",
        "// Allocate memory for matrices on the host\n",
        "float *hA, *hB, *hC;\n",
        "hA = new float[N * N];\n",
        "hB = new float[N * N];\n",
        "hC = new float[N * N];\n",
        "// Read matrices from user\n",
        "cout << \"Enter elements of matrix A (\" << N << \"x\" << N << \"):\" << endl;\n",
        "for (int i = 0; i < N * N; ++i)\n",
        "cin >> hA[i];\n",
        "cout << \"Enter elements of matrix B (\" << N << \"x\" << N << \"):\" << endl;\n",
        "for (int i = 0; i < N * N; ++i)\n",
        "cin >> hB[i];\n",
        "// Allocate memory for matrices on the device\n",
        "int size = N * N * sizeof(float);\n",
        "float *dA, *dB, *dC;\n",
        "cudaMalloc(&dA, size);\n",
        "cudaMalloc(&dB, size);\n",
        "cudaMalloc(&dC, size);\n",
        "// Copy matrices from the host to the device\n",
        "cudaMemcpy(dA, hA, size, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(dB, hB, size, cudaMemcpyHostToDevice);\n",
        "dim3 threadBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "dim3 grid(N / BLOCK_SIZE, N / BLOCK_SIZE);\n",
        "// Execute the matrix multiplication kernel\n",
        "gpuMM<<<grid, threadBlock>>>(dA, dB, dC, N);\n",
        "// Copy the result matrix from the device to the host\n",
        "cudaMemcpy(hC, dC, size, cudaMemcpyDeviceToHost);\n",
        "// Display the result matrix\n",
        "cout << \"\\nResultant matrix:\\n\";\n",
        "for (int row = 0; row < N; row++) {\n",
        "for (int col = 0; col < N; col++) {\n",
        "cout << hC[row * N + col] << \" \";\n",
        "}\n",
        "cout << endl;\n",
        "}\n",
        "// Free device memory\n",
        "cudaFree(dA);\n",
        "cudaFree(dB);\n",
        "cudaFree(dC);\n",
        "// Free host memory\n",
        "delete[] hA;\n",
        "delete[] hB;\n",
        "delete[] hC;\n",
        "cout << \"Finished.\" << endl;\n",
        "return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRSvmcyz3VGd",
        "outputId": "8e431f9b-4118-4456-d2fd-0f1e45dad7a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mult.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_mult.cu -o matrix_mult"
      ],
      "metadata": {
        "id": "sg4Gv-9X3Z4E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_mult\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ1L3o_33en6",
        "outputId": "5d86ef9c-da19-42f6-88b3-ec0bdf4d9516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter size of matrix (N): "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LfTAd-xT3llP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}